{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## In this notebook, you'll download a dataset from Kaggle using the Kaggle API, load it into a Pandas DataFrame, and apply common data cleaning techniques. \n",
    "## Follow the steps and modify them to suit your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Kaggle API Setup\n",
    "## To begin, you need to set up the Kaggle API to download datasets.\n",
    "\n",
    "## 1.1 Install the Kaggle API\n",
    "## If you haven't installed the Kaggle API yet, you can do so using the command below on git bash:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $ !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1.2 Authenticate the Kaggle API\n",
    "# To use the Kaggle API, you'll need to authenticate. Follow these steps:\n",
    "\n",
    "# - Go to https://www.kaggle.com/account, and under **API**, click \"Create New API Token.\"\n",
    "# - This will download a `kaggle.json` file containing your credentials.\n",
    "# - Upload the `kaggle.json` file to your system put them in a location you can easily access.\n",
    "# - Example for where my kaggle json file is located "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload your 'kaggle.json' file first.\n"
     ]
    }
   ],
   "source": [
    "# Once the file is uploaded, run the following code to move it to the correct directory:\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Change the path below if your file is stored in another location.\n",
    "kaggle_json_path = 'kaggle.json'\n",
    "\n",
    "if os.path.exists(kaggle_json_path):\n",
    "    with open(kaggle_json_path, 'r') as f:\n",
    "        kaggle_api = json.load(f)\n",
    "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
    "    with open(os.path.expanduser('~/.kaggle/kaggle.json'), 'w') as f:\n",
    "        json.dump(kaggle_api, f)\n",
    "    os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
    "    print(\"Kaggle API credentials successfully set up!\")\n",
    "else:\n",
    "    print(\"Please upload your 'kaggle.json' file first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1.3 Downloading the Dataset\n",
    "### Now that you're authenticated, you can download your dataset from Kaggle. Replace `your-dataset` below with the dataset's name.\n",
    "\n",
    "### Example Kaggle dataset: 'zillow/zecon' (Real Estate Dataset)\n",
    "### You can search for datasets at https://www.kaggle.com/datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'your-dataset-here'  # Update this with your chosen dataset from Kaggle\n",
    "output_dir = './data'  # Directory to store your downloaded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset using Kaggle API (run the next cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset using Kaggle API\n",
    "!kaggle datasets download -d {dataset} -p {output_dir} --unzip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning: \n",
    "## Now that you have your data lets import important python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python3 (from versions: none)\n",
      "ERROR: No matching distribution found for python3\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import your dataset into a pandas dataframe! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(output_dir, \"your_dataset.csv\")  # Replace with your dataset file\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some useful pandas functions we can use to help in this section: \n",
    "- Removing Duplicates:\n",
    "- Data Type Conversion:\n",
    "- Handling Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values  \n",
    "df.isnull().sum()\n",
    "\n",
    "#Drop rows with missing data:\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "#Fill missing values (e.g., with the mean):\n",
    "df_cleaned = df.fillna(df.mean())\n",
    "\n",
    "# Check for duplicates\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# Data Type Conversions if needed\n",
    "# converting strings to dates\n",
    "\n",
    "# Convert a column to datetime format\n",
    "df_cleaned['date_column'] = pd.to_datetime(df_cleaned['date_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for the numeric column\n",
    "Q1 = df['numeric_column'].quantile(0.25)\n",
    "Q3 = df['numeric_column'].quantile(0.75)\n",
    "\n",
    "# Calculate IQR (Interquartile Range)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the acceptable range for non-outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the dataset to remove outliers\n",
    "df_no_outliers = df[(df['numeric_column'] >= lower_bound) & (df['numeric_column'] <= upper_bound)]\n",
    "\n",
    "# View the cleaned dataset\n",
    "df_no_outliers.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation \n",
    "Here we will be adding and removing unnessary columns on our dataframe \n",
    "I added additional python code you can apply to your dataframe\n",
    "- Creating new Columns \n",
    "- Grouping and Aggregating Statistics \n",
    "- Saving dataset to a new CSV file: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Creating a new column based on conditions\n",
    "df_cleaned['new_column'] = df_cleaned['existing_column'].apply(lambda x: 'Category A' if x > 100 else 'Category B')\n",
    "\n",
    "# Grouping data and calculating mean\n",
    "df_grouped = df_cleaned.groupby('group_column')['numeric_column'].mean()\n",
    "\n",
    "#save dataset to csv\n",
    "cleaned_data_path = os.path.join(output_dir, \"cleaned_dataset.csv\")\n",
    "df_cleaned.to_csv(cleaned_data_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to {cleaned_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
